### Zadanie 5

![](https://i.imgur.com/shbzIlX.png)

** Programy profilujące** -- narzędzia analityczne, zbierające dane na temat działania i wydajności programu w czasie jego wykonywania. Pozwalają ustalić jaka część czasu wykonania programu jest przeznaczona na jego poszczególne funkcje i części, co pomaga w doborze obszaru kodu, którego optymalizacja może przynieść największe korzyści. Na systemach UNIXowych można wykorzystywać program *GPROF*, który generuje dane na temat czasu wykonywania poszczególnych funkcji programu oraz liczby ich funkcji. 

**Profil płaski** (ang. *flat profile*) -- daje informacje o łącznym czasie, jaki program spędził na wykonywaniu poszczególnych funkcji. 
https://sourceware.org/binutils/docs/gprof/Flat-Profile.html

**Profil grafu wywołań** (ang. *call graph*) -- daje informacje o czasie, który został spędzony w obrębie danej funkcji i jej dzieciach (w grafie wywołań funkcji, tj. w funkcjach wywoływanych przez nią).
https://sourceware.org/binutils/docs/gprof/Call-Graph.html

**Opcja kompilatora -pg** -- specjalna flaga kompilatora GCC, konieczna, jeśli chcemy korzystać z programu *gprof* lub innych narzędzi profilujących. Generuje dodatkowy kod, potrzebny programom profilujących do analizowania działania kodu. Opcja musi zostać użyta zarówno przy kompilacji plików źródłowych, jak i przy linkowaniu.
https://gcc.gnu.org/onlinedocs/gcc/Instrumentation-Options.html#Instrumentation-Options

**Zliczanie interwałowe** (ang. *interval timing*) -- metoda zliczania czasu wykonania programu. Skompilowany program przechowuje licznik dla każdej funkcji, który mierzy czas, który został w niej spędzony. System operacyjny przerywa działania programu co określony czas (*interval*), zwykle co $1.0$-$10.0$ ms. Następnie określa, jaka funkcja była wykonywana w czasie przerwania i zwiększa przypisany jej licznik o $1$.

Metoda nie jest zbyt dokładna. Może się zdarzyć, że między przerwaniami zostanie wywołana i zakończona jedna lub więcej funkcji, przez co przypisane im liczniki nie zostaną zwiększone. Satysfakcjonujące rezultaty otrzymujemy, wykorzystując tę metodę do badania programów, których czas wykonania jest stosunkowo długi, przekraczający $1$ s.

**Jak w 5.14.2 zidentyfikowano przy pomocy programu profilującego, które procedury należy zoptymalizować?**

Autorzy użyli programu profilującego do systematycznego wyszukiwania **bottlenecków**, czyli fragmentów programu, które najbardziej wpływają na długość czasu jego wykonania. Na początku zaobserwowali, że najwięcej czasu program spędza na sortowaniu danych algorytmem *insert sort*, który ma złośoność $O(n^2)$. Zmiana algorytmu sortującego na biblioteczną implmenetację *quicksorta* skróciło czas działania programu z trzech minut do niecałych $5$ sekund.

Kolejnym krokiem było ponowne przetestowanie programu pod kątem możliwych *bottlenecków* i wychwycenie, że tym razem możliwym kandydatem do optymalizacji było przeszukiwanie listy w sposób rekurencyjny. Zamiana algorytmu na wersję iteracyjną (z drobną pomyłką po drodze) skróciła działanie programu do $4.2$ sekundy.

Następną optymalizacją była modyfikacja funkcji hashującej w tablicy na taką, która zmniejszała liczbę kolizji indeksów. Ponownie skróciło to czas do $0.4$ sekundy.

Ostatnią optymalizacją było zmniejszenie złożoności asymptotycznej funkcji przekształcającej duze litery na małe z $O(n^2)$, co ostatecznie skróciło czsa działania programu do $0.2$ sekundy.

Ostatecznie ich działania można podsumować następująco:
* stosowanie narzędzia profilującego do wyszukiwania potencjalnych *bootlenecków* w programie,
* usuwanie *bottlenecków* poprzez usprawnianie algorytmów, zmniejszanie złożoności czasowej lub stosowanie tricków optymalizacyjnych,
* wielokrotne testowanie programu na różnych zestawach danych, by wykryć jak najszersz spektrum *bootlenecków* (w omawianym przypadku testowanie tekstów z krótkimi słowami mogłoby utrudnić zauważenie *bootlenecka* przy zamianie dużych liter na małe -- algorytm miał złożoność kwadratową),
* przeprowadzanie dokładnej analizy działania algorytmów (tutaj w przypadku przeszukiwania listy okazało się, że dodawanie elementów na koniec listy ustawiało je w porządku malejącym względem częstości występowania, co przyspieszało działanie algorytmu ułatwiając mu odszukiwanie częstych przypadków).

Największy efekt przyniosły optymalizacje złożoności asymptotycznej algorytmów, np. sortowania i zmiany wielkości liter, a także tych fragmentów kodu, które stanowiły największą część czasu działania programu (zgodnie z **prawem Amdhala**).

![](https://i.imgur.com/0AyS2kG.png)
![](https://i.imgur.com/ekTAzU2.png)
