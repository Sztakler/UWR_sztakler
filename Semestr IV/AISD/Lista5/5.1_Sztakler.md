## Zadanie 1

![](https://i.imgur.com/saz5Fmv.png)

### Wstęp

W modelu drzew decyzyjnych przedstawiamy operacje porównania danych elementów jako wierzchołki drzewa, a obliczenia wykonywane przez algorytm między porównaniami jako jego krawędzie. W takim wypadku każdy wierzchołek odpowiada pewnej decyzji, podejmowanej przez algorytm, która determinuje zmianę wyniku.

Przebieg działania algorytmu możemy odczytać przez wyszukanie drogi od korzenia drzewa aż do jakiegoś liścia. Każdy liść odpowiada innemu wynikowi algorytmu.

### Problem znajdowania otoczki wypukłej

Po otrzymaniu zestawu danych, w postaci zbioru punktów $P=\{p_1=(x_1,y_1), p_2=(x_2,y_2), ..., p_n=(x_n,y_n)\}$ należy wyznaczyć najmniejszy wielokąt wypukły, w którym zawierają się wszystkie punkty z zestawu danych.

### Rozwiązanie problemu znajdowania otoczki wypukłej w modelu drzew decyzyjnych

Pamiętamy, że w modelu drzew decyzyjnych relacje między danymi wejściowymi determinują przebieg algorytmu, a zatem wyznaczają ścieżkę od korzenia do liścia w drzewie decyzyjnym tego algorytmu. Rozważmy problem znajdowania otoczki wypukłej w modelu drzew decyzyjnych.

Porównania będziemy wykonywać między danymi, tzn. punktami ze zbioru wejściowego. Co to znaczy porównać punkty? Nie wiadomo, ale możemy zauważyć, że mamy mocno ograniczoną pulę możliwości. Skoro nie możemy wykonywać żadnych operacji na danych (model drzew decyzyjnych zakłada jedynie operacje porównania), to możemy pracować tylko na *surowych* danych. To ogranicza nas do czterch możliwych porównań:
* współrzędna $x$ ze współrzędną $x$,
* współrzędna $y$ ze współrzędną $y$,
* współrzędna $x$ ze współrzędna $y$,
* współrzędna $y$ ze współrzędna $x$.

Zauważmy, że skoro relacje między danymi jednoznacznie wyznaczają wynik algorytmu, to dla dowolnego zestawu punktów spełniających te same relacje, algorytm powinien zwrócić ten sam wynik. Zauważmy jednak, że w kontekście znajdowania otoczki wypukłej stosunkowo łatwo jest znaleźć na to kontrprzykład.

Rozważmy dwa zestawy danych: $D = \{p_1=(0,0), p_2=(2,4), p_3=(6,8), p_4=(10,12)\}$ oraz $D'=\{q_1==(0,0), q_2=(2,4), q_3=(6,7), q_4=(10,12)\}$. Algorytm zwróci dla nich następujące dwie otoczki wypukłe (zielona dla punktów $p$ i czerwona dla punktów $q$).

![](https://i.imgur.com/xVMXM91.png)


Zauważmy, że dla obu zestawów danych zachodzą następujące nierówności po współrzędnych $x$ i $y$:

Dla punktów $p$:
$x_1 < x_2 < x_3 < x_4$. bo $0 < 2 < 6 < 10$
$y_1 < y_3 < y_4 < y_2$, bo $0 < 4 < 8 < 12$

Dla punktów $q$:
$x_1 < x_2 < x_3 < x_4$. bo $0 < 2 < 6 < 10$
$y_1 < y_3 < y_4 < y_2$, bo $0 < 4 < 7 < 12$

Musimy jeszcze rozważyć relacje między współrzędnymi $x$ i $y$ oraz $y$ i $x$. W obu zestawach znajdują się punkty, w których współrzędna $x$ jest mniejsza od współrzędnej $y$ (poza punktem (0,0). Zauważmy, że zestawy punktów $P$ i $Q$ różnią się jednym punktem $p_3=q_3$, nazwijmy go $r$, więc jego współrzędne są jedynymi, które mogły zmienić coś w tych nierównościach. Przeanalizujmy je:

Dla współrzędnych $x$ punktów $p$ w porównaniu ze współrzędną $y$ punktu $r$:
$x_1 < x_2 < y_r < x_4$, bo $0 < 2 < 8 < 10$

Dla współrzędnych $y$ punktów $p$ w porównaniu ze współrzędną $x$ punktu $r$:
$y_1 < y_2 < x_r < y_4$, bo $0 < 4 < 6 < 12$

Dla współrzędnych $x$ punktów $q$ w porównaniu ze współrzędną $y$ punktu $r$:
$x_1 < x_2 < y_r < x_4$, bo $0 < 2 < 6 < 10$

Dla współrzędnych $y$ punktów $q$ w porównaniu ze współrzędną $x$ punktu $r$:
$y_1 < y_2 < x_r < y_4$, bo $0 < 4 < 7 < 12$

Kolejne nierówności wyznaczają jednakową drogę od korzenia drzewa decyzyjnego do tego samego liścia dla obu zestawów danych. Skoro obie ścieżki kończą się w tym samym liściu, to powinniśmy otrzymać ten sam wynik, ale widzimy, że algorytm zwrócił dwie różne otoczki wypukłe. W takim razie znaleźliśmy kontrprzykład dla tezy, że problem znajdowania otoczki wypukłej można rozważać w modelu drzew porównań.
